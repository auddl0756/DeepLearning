# -*- coding: utf-8 -*-
"""Multi_Classification_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f4patLqr49oOteioc40QPLgEhI9RE87g
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import zipfile
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import numpy as np
import matplotlib.pyplot as plt

local_zip = '/content/drive/My Drive/test/assignment2.zip'

zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

#!ls
#!ls /content/drive/'My Drive'/test
#!ls /content/drive/'My Drive'/test/'assignment2.zip (Unzipped Files)'/test
!ls /tmp/test
#!ls /tmp/test/Airbus

"""

제조사별 train 이미지들이 있는 디렉토리의 경로를 d0,d1,...d9에 담는다.
제조사별 test 이미지들이 있는 디렉토리의 경로를 D0,D1,...D9에 담는다.
d0,d1,...d9를 train_dirs에 담는다.
D0,D1,...,D9를 test_dirs에 담는다.
"""

#base_dir = '/tmp/dataset'
base_dir='/tmp'
train_dir = os.path.join(base_dir, 'train')
test_dir = os.path.join(base_dir, 'test')

!ls /tmp
#!ls /tmp/train/Airbus

d0=os.path.join(train_dir,'Airbus')           #train_Airbus_dir
d1=os.path.join(train_dir,'Boeing')           #train_Boeing_dir
d2=os.path.join(train_dir,'Canadair')         #train_Canadair_dir
d3=os.path.join(train_dir,'Embraer')          #train_Embraer_dir=
d4=os.path.join(train_dir,'Eurofighter')      #train_Eurofighter_dir=
d5=os.path.join(train_dir,'McDonnell_Douglas')#train_McDonnell_Douglas_dir=
d6=os.path.join(train_dir,'Lockheed_Martin')  #train_Lockheed_Martin_dir=
d7=os.path.join(train_dir,'Robin')            #train_Robin_dir=
d8=os.path.join(train_dir,'Saab')             #train_Saab_dir=
d9=os.path.join(train_dir,'Yakovlev')         #train_Yakovlev_dir=


D0=os.path.join(test_dir,'Airbus')           #train_Airbus_dir
D1=os.path.join(test_dir,'Boeing')           #train_Boeing_dir
D2=os.path.join(test_dir,'Canadair')         #train_Canadair_dir
D3=os.path.join(test_dir,'Embraer')          #train_Embraer_dir=
D4=os.path.join(test_dir,'Eurofighter')      #train_Eurofighter_dir=
D5=os.path.join(test_dir,'McDonnell_Douglas')#train_McDonnell_Douglas_dir=
D6=os.path.join(test_dir,'Lockheed_Martin')  #train_Lockheed_Martin_dir=
D7=os.path.join(test_dir,'Robin')            #train_Robin_dir=
D8=os.path.join(test_dir,'Saab')             #train_Saab_dir=
D9=os.path.join(test_dir,'Yakovlev')         #train_Yakovlev_dir=


train_dirs=[d0,d1,d2,d3,d4,d5,d6,d7,d8,d9]
test_dirs=[D0,D1,D2,D3,D4,D5,D6,D7,D8,D9]

#print(len(train_dirs))
#print(train_dirs[0])

# !pwd

"""제조사별 비행기 이미지들이 있는 각 디렉토리의 파일명들을 모두 temp에 담고 temp를 train_fnames 리스트,test_fnames 리스트에 담는다.

"""

train_fnames=[]
test_fnames=[]

for i in train_dirs:
  temp=os.listdir(i)
  train_fnames.append(temp)

for i in test_dirs:
  temp=os.listdir(i)
  test_fnames.append(temp)


#print(train_fnames[0][1])

#classNames=['Airbus', 'Boeing', 'Canadair', 'Embraer', 'Eurofighter', 'Lockhed_Martin', 'McDonel_Douglas', 'Robin', 'Sab', 'Yakovlev']

"""train 이미지들과 test 이미지들의 실제 이미지의 경로를 얻은 다음 tensorflow.keras.preprocessing.image.load_img 모듈을 활용하여 실제 이미지 배열(=리스트=행렬)을 얻고 256.0으로 나눠서 normalize한다. 
그리고 train_images와 test_images 배열에 담는다.
test_labels,train_labels도 저장한다.
(label은 ['Airbus', 'Boeing', 'Canadair', 'Embraer', 'Eurofighter', 'Lockhed_Martin', 'McDonel_Douglas', 'Robin', 'Sab', 'Yakovlev'순으로 0~9까지 배정함.)
"""

from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals

print(tf.__version__)
import matplotlib.image as mpimg

from tensorflow.keras.preprocessing.image import img_to_array, load_img

train_images=[]
train_labels=[]
test_images=[]
test_labels=[]
flag=0

for i in range(10):
  subdir=train_dirs[i]
  for fname in train_fnames[i]:
    img_path=os.path.join(subdir,fname)
    
    img = load_img(img_path, target_size=(200,200))
    x = img_to_array(img)
   
    x/=256.0
    
    #img=np.array(img)
    train_images.append(x)
    train_labels.append(i) 

for i in range(10):
  subdir=test_dirs[i]
  for fname in test_fnames[i]:
    img_path=os.path.join(subdir,fname)
   
    img = load_img(img_path, target_size=(200,200))
    x = img_to_array(img)
    x/=256.0
    
    #img=np.array(img)
    test_images.append(x)
    test_labels.append(i) 

train_images=np.array(train_images)
train_labels=np.array(train_labels)
test_images=np.array(test_images)
test_labels=np.array(test_labels)


train_images.shape

"""비행기 이미지들이 제대로 저장되었는지 확인하기 위해 비행기 이미지들을 출력해 보았음."""

plt.figure()
plt.imshow(train_images[0])
#plt.imshow(test_images[0])
plt.colorbar()
plt.show()

plt.figure(figsize=(10,10))
for i in range(20):
  plt.subplot(5,5,i+1)
  plt.imshow(train_images[i],cmap=plt.cm.binary)
plt.show()

from tensorflow import keras

"""여러가지 CNN 모델을 만들어 보았음. 최종적으로 5번째 모델을 사용하여 81퍼센트의 테스트 정확도와 0.62의 테스트 loss 값을 갖고 90퍼센트의 train 정확도를 갖는 모델을 얻었다. overfitting을 줄이기 위해 dropout을 사용해 보았고, parameter수가 너무 많아지지 않도록 신경망을 구성하였다.
CNN을 거친 뒤에 Flatten하여 Dense 신경망에 넣고 최종적으로 softmax를 통해 0~9 레이블 중 어떤 확률이 가장 높은지 얻는 방식으로 구현하였다.
"""

####### MODEL -1 accuracy: 0.41 ,loss:1.48#######  

# model=keras.Sequential([
#   keras.layers.Flatten(input_shape=(200,200,3)),
#   keras.layers.Dense(128,activation='relu'),
#   keras.layers.Dropout(0.5),
#   keras.layers.Dense(128,activation='relu'),
#   keras.layers.Dropout(0.5),
#   keras.layers.Dense(10,activation='softmax')
# ])



####### MODEL -2 test accuracy:0.65 (150x300)####### 

# from tensorflow.keras import layers
# # from tensorflow.keras import Model
# from tensorflow.keras import models

# model = models.Sequential()
# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150,150,3)))
# #model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150,300,3)))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(64, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(64, (3, 3), activation='relu'))

# model.add(layers.Flatten())
# model.add(layers.Dense(64,activation='relu'))
# model.add(layers.Dense(10, activation='softmax'))



####### MODEL -3 test accuracy:0.71  drop out,CNN층 추가 ####### 

# from tensorflow.keras import layers
# # from tensorflow.keras import Model
# from tensorflow.keras import models

# model = models.Sequential()

# model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(200,200,3)))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(32, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(16, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(32, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(16, (3, 3), activation='relu'))


# model.add(layers.Flatten())
# model.add(layers.Dense(256,activation='relu'))
# model.add(layers.Dropout(0.5))
# #keras.layers.Dropout(0.5),
# model.add(layers.Dense(256,activation='relu'))
# model.add(layers.Dropout(0.5))
# model.add(layers.Dense(64,activation='relu'))
# model.add(layers.Dense(10, activation='softmax'))

####### MODEL -4 test accuracy:0.74 drop out,CNN층 더 많이 추가..DENSE층도 더많이 추가 ####### 

# from tensorflow.keras import layers
# # from tensorflow.keras import Model
# from tensorflow.keras import models

# model = models.Sequential()

# model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(200,200,3)))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(32, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(64, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(32, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(64, (3, 3), activation='relu'))
# # model.add(layers.MaxPooling2D((2, 2)))
# # model.add(layers.Conv2D(32, (3, 3), activation='relu'))


# model.add(layers.Flatten())
# model.add(layers.Dense(512,activation='relu'))
# model.add(layers.Dropout(0.5))
# #keras.layers.Dropout(0.5),
# model.add(layers.Dense(128,activation='relu'))
# model.add(layers.Dropout(0.5))

# model.add(layers.Dense(10, activation='softmax'))



####### MODEL -5 test accuracy:0.74 drop out,CNN층 더 많이 추가..DENSE층도 더많이 추가 + 레귤레이션 ####### 

#from tensorflow.keras import layers
#from tensorflow.keras import models

# model = models.Sequential()

# model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(200,200,3)))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Dropout(0.5))
# model.add(layers.Conv2D(32, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(64, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Dropout(0.5))
# model.add(layers.Conv2D(32, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(64, (3, 3), activation='relu'))
# # model.add(layers.MaxPooling2D((2, 2)))
# # model.add(layers.Conv2D(32, (3, 3), activation='relu'))

# model.add(layers.Flatten())
# model.add(layers.Dense(512,kernel_regularizer=keras.regularizers.l2(0.001),activation='relu'))
# model.add(layers.Dropout(0.5))
# #keras.layers.Dropout(0.5),
# model.add(layers.Dense(128,kernel_regularizer=keras.regularizers.l2(0.001),activation='relu'))
# #model.add(layers.Dense(64,kernel_regularizer=keras.regularizers.l2(0.001),activation='relu'))
# model.add(layers.Dropout(0.5))

# model.add(layers.Dense(10, activation='softmax'))


####### MODEL -5 test accuracy:0.81  loss= 0.62 오버피팅 방지 위해 parameter 줄여서 학습 ####### 

from tensorflow.keras import layers
# from tensorflow.keras import Model
from tensorflow.keras import models

model = models.Sequential()

model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(200,200,3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.5))

model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(200,200,3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.5))

model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(200,200,3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.5))

model.add(layers.Flatten())
model.add(layers.Dense(64,kernel_regularizer=keras.regularizers.l2(0.001),activation='relu'))
#model.add(layers.Dropout(0.5))

#model.add(layers.Dense(128,kernel_regularizer=keras.regularizers.l2(0.001),activation='relu'))
#model.add(layers.Dropout(0.5))
# #model.add(layers.Dense(64,kernel_regularizer=keras.regularizers.l2(0.001),activation='relu'))


model.add(layers.Dense(10, activation='softmax'))

model.summary()

"""만든 신경망 모델을 컴파일.
optimizer는 adam을 사용, loss function은 cross entropy를 사용하였음.

"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
max_acc=0   #테스트 정확도의 최댓값을 저장할 변수
arg_max=0   #테스트 정확도가 최대일 때의 epoch 값을 저장할 변수

"""model에 train image와 그에 대한 분류값인 train label을 넘겨주고 fit() 메소드를 호출하면 training이 시작된다. 




"""

#e: epoch
#test_loss : test loss
#test_acc : test accuracy
#max_acc : test accuracy의 최대값
#arg_max : test accuracy가 최대일 때 epoch값

for e in range(200):
  model.fit(train_images,train_labels,epochs=1)
  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
  if max_acc<test_acc:
    arg_max=e
    max_acc=test_acc

  print('\n epoch =',e, '테스트 정확도:', test_acc)

print("최대 정확도: ",max_acc,"그 때의 epoch= ",arg_max)

"""epoch가 증가할수록 test accuracy가 증가하는 경향을 보여서 추가로 train을 더 진행하였음."""

#loss_tf = tf.convert_to_tensor(loss_np, np.float32)
#train_images_tf=tf.convert_to_tensor(train_images)

for e in range(200,300):
  model.fit(train_images,train_labels,epochs=1)
  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
  if max_acc<test_acc:
    arg_max=e
    max_acc=test_acc

  print('\n epoch =',e, '테스트 정확도:', test_acc)

print("최대 정확도: ",max_acc,"그 때의 epoch= ",arg_max)

#loss_tf = tf.convert_to_tensor(loss_np, np.float32)
#train_images_tf=tf.convert_to_tensor(train_images)

for e in range(300,600):
  model.fit(train_images,train_labels,epochs=1)
  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
  if max_acc<test_acc:
    arg_max=e
    max_acc=test_acc

  print('\n epoch =',e, '테스트 정확도:', test_acc)

print("최대 정확도: ",max_acc,"그 때의 epoch= ",arg_max)

#loss_tf = tf.convert_to_tensor(loss_np, np.float32)
#train_images_tf=tf.convert_to_tensor(train_images)

for e in range(600,1000):
  model.fit(train_images,train_labels,epochs=1)
  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
  if max_acc<test_acc:
    arg_max=e
    max_acc=test_acc

  print('\n epoch =',e, '테스트 정확도:', test_acc)

print("최대 정확도: ",max_acc,"그 때의 epoch= ",arg_max)

#loss_tf = tf.convert_to_tensor(loss_np, np.float32)
#train_images_tf=tf.convert_to_tensor(train_images)

for e in range(1000,2000):
  model.fit(train_images,train_labels,epochs=1)
  test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
  if max_acc<test_acc:
    arg_max=e
    max_acc=test_acc

  print('\n epoch =',e, '테스트 정확도:', test_acc)

print("최대 정확도: ",max_acc,"그 때의 epoch= ",arg_max)

# for e in range(0,3000):
#   model.fit(train_images,train_labels,epochs=1)
#   test_loss, test_acc = model.evaluate(test_images,  test_labels)
#   if max_acc<test_acc:
#     arg_max=e
#     max_acc=test_acc

#   #print('\n epoch =',e, '테스트 정확도:', test_acc)

# print("최대 정확도: ",max_acc,"그 때의 epoch= ",arg_max)

predictions=model.predict(test_images)
predictions[0]
np.argmax(predictions[0])
test_labels[0]

"""분류 예측해보기.(tensorflow 공식 홈페이지의 튜토리얼에서 참고. https://www.tensorflow.org/tutorials/keras/classification)
plot_image함수,plot_value_array함수가 이미지의 분류값이 옳은지(blue color), 틀렸는지(red color)를 그려준다.

"""

def plot_image(i, predictions_array, true_label, img):
  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(classNames[predicted_label],
                                100*np.max(predictions_array),
                                classNames[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array[i], true_label[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

"""30개의 비행기 이미지에 대해 모델의 예측값을 출력해 보았음.


"""

for i in range(0,10):
  plt.figure(figsize=(6,3))
  plt.subplot(1,2,1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(1,2,2)
  plot_value_array(i, predictions,  test_labels)
  plt.show()

for i in range(500,510):
  plt.figure(figsize=(6,3))
  plt.subplot(1,2,1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(1,2,2)
  plot_value_array(i, predictions,  test_labels)
  plt.show()

for i in range(1000,1010):
  plt.figure(figsize=(6,3))
  plt.subplot(1,2,1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(1,2,2)
  plot_value_array(i, predictions,  test_labels)
  plt.show()

"""분류 결과를 보면 특이한 이미지들(실내 사진, 비행기 두대가 겹쳐있는 사진 등)은 분류가 틀렸지만 약간의 확률 차이로 틀린 것을 확인할 수 있고, 대체로 옳게 분류한 것을 확인할 수 있다."""

